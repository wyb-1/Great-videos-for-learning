# 第三代神经网络：脉冲神经网络

## 1、最近相关机器学习顶会视频

- [20200601:通过混合转换训练深度脉冲神经网络（SNN）](https://www.youtube.com/watch?v=LwQ-0liDwiQ)
  - 项目摘要：该项目的目标概述如下：1.在对流行的人工神经网络架构进行仔细转换的基础上，分析卷积钉刺神经网络（CSNN）进行图像分类的性能，这对Imagenet数据集的分类具有可喜的成果。2.在转换后的网络上执行增量依赖于尖峰时序的反向传播（STDB），以获得在几个时期内收敛并且需要较少时间步进行输入处理的SNN。3.在CIFAR-10和MNIST上针对VGG和Resnet体系结构进行实验。动机：近年来，Spiking神经网络（SNN）在通过事件驱动的神经形态硬件实现低功耗机器智能方面取得了巨大成功。二进制基于“全有或全无”峰值的通信加上稀疏的时间处理，使SNN成为传统ANN的低功耗替代品。尽管提高了能效，但训练SNN仍然是一个挑战，因为尖峰神经元（通常建模为泄漏的积分生火（LIF）或积分生火（IF ））与基于梯度下降的反向传播不兼容。在这项工作中，我们提出了一种混合训练技术，该技术结合了ANN-SNN转换和基于尖峰的反向传播，可减少总延迟并减少训练收敛所需的精力。我们使用ANN-SNN转换作为初始化步骤，然后进行基于尖峰的反向传播增量训练（由于前期初始化，收敛到最优精度，且历时很少）。从本质上讲，与仅通过转换或仅基于尖峰的反向传播从头训练的模型相比，采用转换的SNN并使用反向传播对其进行增量训练的混合方法可提高能源效率并提高准确性。数据需求和获取计划：我们计划逐步提高数据集的复杂性。我们计划在CIFAR-10和MNIST数据集上测试初始的ANN模型。这项工作的未来范围包括在ImageNet和CIFAR-100上进行测试。与仅通过转换或仅基于尖峰的反向传播从头开始训练的模型相比，我们采用混合SNN并使用反向传播对其进行增量训练的混合方法可提高能源效率并提高准确性。数据需求和获取计划：我们计划逐步提高数据集的复杂性。我们计划在CIFAR-10和MNIST数据集上测试初始的ANN模型。这项工作的未来范围包括在ImageNet和CIFAR-100上进行测试。与仅通过转换或仅基于尖峰的反向传播从头开始训练的模型相比，我们采用混合SNN并使用反向传播对其进行增量训练的混合方法可提高能源效率并提高准确性。数据需求和获取计划：我们计划逐步提高数据集的复杂性。我们计划在CIFAR-10和MNIST数据集上测试初始的ANN模型。这项工作的未来范围包括在ImageNet和CIFAR-100上进行测试。
